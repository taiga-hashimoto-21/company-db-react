const { MeiliSearch } = require('meilisearch')
const { Pool } = require('pg')
require('dotenv').config({ path: '.env.local' })

// MeiliSearch client
const client = new MeiliSearch({
  host: process.env.MEILISEARCH_HOST || 'http://127.0.0.1:7700',
  apiKey: process.env.MEILISEARCH_API_KEY || 'your-master-key-here'
})

// PostgreSQL pool
const pool = new Pool({
  connectionString: process.env.DATABASE_URL,
  ssl: process.env.NODE_ENV === 'production' ? { rejectUnauthorized: false } : false
})

async function importPRTimesToMeiliSearch() {
  console.log('ğŸš€ Starting PRTimes data import to MeiliSearch...')

  try {
    // PostgreSQLã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—
    console.log('ğŸ“Š Fetching data from PostgreSQL...')
    const client_pg = await pool.connect()

    const result = await client_pg.query(`
      SELECT * FROM prtimes_companies
      ORDER BY delivery_date DESC
    `)

    client_pg.release()

    console.log(`ğŸ“Š Found ${result.rows.length} PRTimes companies to import`)

    if (result.rows.length === 0) {
      console.log('âš ï¸ No data to import')
      return
    }

    // MeiliSearchã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ/å–å¾—
    console.log('ğŸ” Setting up MeiliSearch index...')
    const indexName = 'prtimes_companies'

    try {
      await client.createIndex(indexName, { primaryKey: 'id' })
      console.log(`âœ… Created new index: ${indexName}`)
    } catch (error) {
      if (error.code === 'index_already_exists') {
        console.log(`âœ… Using existing index: ${indexName}`)
      } else {
        throw error
      }
    }

    const index = client.index(indexName)

    // é‡è¤‡é™¤å»ã‚­ãƒ¼ç”Ÿæˆé–¢æ•°ï¼ˆå…ƒã®ãƒ­ã‚¸ãƒƒã‚¯ã¨åŒã˜ï¼‰
    function extractDomain(url) {
      if (!url || !url.trim() || url === '-') return null
      try {
        const cleanUrl = url.trim()
        const fullUrl = cleanUrl.match(/^https?:\/\//) ? cleanUrl : `https://${cleanUrl}`
        const domain = new URL(fullUrl).hostname.toLowerCase()
        return domain.replace(/^www\./, '')
      } catch {
        return null
      }
    }

    function normalizeCompanyName(name) {
      if (!name || !name.trim()) return 'no-name'
      return name.trim()
        .toLowerCase()
        .replace(/æ ªå¼ä¼šç¤¾|ï¼ˆæ ªï¼‰|\(æ ª\)|æœ‰é™ä¼šç¤¾|åˆåŒä¼šç¤¾|co\.,ltd\.|ltd\.|inc\.|corp\./g, '')
        .replace(/\s+/g, '')
    }

    // ãƒ‡ãƒ¼ã‚¿å¤‰æ›ï¼ˆãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸URLãŒ"-"ã®è¡Œã‚’é™¤å¤–ï¼‰
    console.log('ğŸ”„ Transforming data for MeiliSearch...')
    const documents = result.rows
      .filter(row => {
        // ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸URLãŒ"-"ã‚„ç©ºã®å ´åˆã¯é™¤å¤–
        return row.company_website &&
               row.company_website.trim() !== '' &&
               row.company_website.trim() !== '-'
      })
      .map(row => {
        // å…ƒã®ãƒ­ã‚¸ãƒƒã‚¯ã¨åŒã˜é‡è¤‡é™¤å»ã‚­ãƒ¼ã‚’ç”Ÿæˆ
        const domain = extractDomain(row.company_website)
        const normalizedName = normalizeCompanyName(row.company_name)
        const dedupeKey = domain || normalizedName || `fallback_${row.id}`

        return {
          id: row.id,
          deliveryDate: row.delivery_date,
          deliveryDateTimestamp: row.delivery_date ? new Date(row.delivery_date).getTime() : 0,
          pressReleaseUrl: row.press_release_url,
          pressReleaseTitle: row.press_release_title,
          pressReleaseType: row.press_release_type,
          pressReleaseCategory1: row.press_release_category1,
          pressReleaseCategory2: row.press_release_category2,
          companyName: row.company_name,
          companyWebsite: row.company_website,
          businessCategory: row.business_category,
          industryCategory: row.industry_category,
          subIndustryCategory: row.sub_industry_category,
          industry: row.business_category || row.industry_category,
          address: row.address,
          phoneNumber: row.phone_number,
          representative: row.representative,
          listingStatus: row.listing_status,
          capitalAmountText: row.capital_amount_text,
          establishedDateText: row.established_date_text,
          capitalAmountNumeric: row.capital_amount_numeric || 0,
          establishedYear: row.established_year || 0,
          establishedMonth: row.established_month || 0,
          createdAt: row.created_at,
          batchId: row.batch_id,
          dedupeKey: dedupeKey  // é‡è¤‡é™¤å»ã‚­ãƒ¼è¿½åŠ 
        }
      })

    console.log(`ğŸ“Š Filtered ${result.rows.length} rows to ${documents.length} documents (excluded ${result.rows.length - documents.length} rows with invalid website)`)

    // ãƒãƒƒãƒã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    console.log('ğŸ“¥ Importing documents to MeiliSearch...')
    const batchSize = 1000
    const totalBatches = Math.ceil(documents.length / batchSize)

    for (let i = 0; i < totalBatches; i++) {
      const start = i * batchSize
      const end = Math.min(start + batchSize, documents.length)
      const batch = documents.slice(start, end)

      console.log(`ğŸ“¦ Importing batch ${i + 1}/${totalBatches} (${batch.length} documents)`)

      const task = await index.addDocuments(batch)
      console.log(`âœ… Batch ${i + 1} uploaded (task: ${task.taskUid})`)
    }

    // ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­å®š
    console.log('âš™ï¸ Configuring search settings...')

    // æ¤œç´¢å¯èƒ½å±æ€§
    await index.updateSearchableAttributes([
      'companyName',
      'pressReleaseTitle',
      'businessCategory',
      'industryCategory',
      'address',
      'representative'
    ])

    // ãƒ•ã‚£ãƒ«ã‚¿å¯èƒ½å±æ€§
    await index.updateFilterableAttributes([
      'businessCategory',
      'industryCategory',
      'pressReleaseType',
      'listingStatus',
      'capitalAmountNumeric',
      'establishedYear',
      'deliveryDateTimestamp'
    ])

    // ã‚½ãƒ¼ãƒˆå¯èƒ½å±æ€§
    await index.updateSortableAttributes([
      'deliveryDateTimestamp',
      'capitalAmountNumeric',
      'establishedYear'
    ])

    // çµ±è¨ˆå–å¾—
    const stats = await index.getStats()
    console.log(`ğŸ‰ Import completed!`)
    console.log(`ğŸ“Š Total documents: ${stats.numberOfDocuments}`)

    console.log('âœ… PRTimes MeiliSearch import finished successfully!')

  } catch (error) {
    console.error('âŒ Import failed:', error)
    process.exit(1)
  } finally {
    await pool.end()
  }
}

// ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
if (require.main === module) {
  importPRTimesToMeiliSearch()
    .then(() => {
      console.log('ğŸ Script finished')
      process.exit(0)
    })
    .catch(error => {
      console.error('ğŸ’¥ Script failed:', error)
      process.exit(1)
    })
}

module.exports = { importPRTimesToMeiliSearch }