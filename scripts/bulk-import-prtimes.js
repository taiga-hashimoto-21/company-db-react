const { Pool } = require('pg')
const fs = require('fs')
const path = require('path')
const readline = require('readline')

// „Éá„Éº„Çø„Éô„Éº„ÇπÊé•Á∂ö
const pool = new Pool({
  connectionString: process.env.DATABASE_URL,
  ssl: process.env.NODE_ENV === 'production' ? { rejectUnauthorized: false } : false
})

function parseCSVLine(line) {
  const result = []
  let current = ''
  let inQuotes = false
  let i = 0

  while (i < line.length) {
    const char = line[i]

    if (char === '"' && (i === 0 || line[i - 1] === ',')) {
      inQuotes = true
    } else if (char === '"' && inQuotes && (i === line.length - 1 || line[i + 1] === ',')) {
      inQuotes = false
    } else if (char === ',' && !inQuotes) {
      result.push(current.trim())
      current = ''
    } else {
      current += char
    }

    i++
  }

  result.push(current.trim())
  return result
}

async function bulkImportPRTimes(csvFilePath) {
  if (!fs.existsSync(csvFilePath)) {
    console.error('‚ùå File not found:', csvFilePath)
    process.exit(1)
  }

  const client = await pool.connect()
  let successCount = 0
  let errorCount = 0
  let totalLines = 0

  try {
    console.log('üöÄ Starting bulk import of PRTimes data...')
    console.log('üìÅ File:', csvFilePath)

    const startTime = Date.now()

    // „Éê„ÉÉ„ÉÅID„ÇíÁîüÊàê
    const batchId = 'seed_' + Date.now()

    // „Éï„Ç°„Ç§„É´„Çµ„Ç§„Ç∫„Å®Ë°åÊï∞„Çí„ÉÅ„Çß„ÉÉ„ÇØ
    const stats = fs.statSync(csvFilePath)
    console.log('üìä File size:', Math.round(stats.size / 1024 / 1024), 'MB')

    // Ë°åÊï∞„Çí„Ç´„Ç¶„É≥„ÉàÔºàÈ´òÈÄüÔºâ
    console.log('üî¢ Counting lines...')
    const lineCount = await new Promise((resolve, reject) => {
      let count = 0
      const stream = fs.createReadStream(csvFilePath)
      const rl = readline.createInterface({
        input: stream,
        crlfDelay: Infinity
      })

      rl.on('line', () => count++)
      rl.on('close', () => resolve(count))
      rl.on('error', reject)
    })

    totalLines = Math.max(0, lineCount - 1) // „Éò„ÉÉ„ÉÄ„ÉºÈô§„Åè
    console.log(`üìù Total data rows: ${totalLines.toLocaleString()}`)

    // „Ç¢„ÉÉ„Éó„É≠„Éº„ÉâÂ±•Ê≠¥„ÇíË®òÈå≤
    const uploadResult = await client.query(`
      INSERT INTO prtimes_uploads (filename, total_records, file_size_kb, uploaded_by, batch_id, status)
      VALUES ($1, $2, $3, $4, $5, 'processing')
      RETURNING id
    `, [
      path.basename(csvFilePath),
      totalLines,
      Math.round(stats.size / 1024),
      'seed-script',
      batchId
    ])

    const uploadId = uploadResult.rows[0].id

    // „Ç§„É≥„Éá„ÉÉ„ÇØ„ÇπÁÑ°ÂäπÂåñ„ÅßÈ´òÈÄüÂåñ
    console.log('‚è∏Ô∏è Temporarily disabling indexes for faster import...')
    try {
      await client.query('DROP INDEX IF EXISTS idx_prtimes_company_name_temp')
      await client.query('DROP INDEX IF EXISTS idx_prtimes_website_temp')
    } catch (e) {
      console.log('Index drop skipped (may not exist)')
    }

    // ‰∏ÄÊôÇ„ÉÜ„Éº„Éñ„É´‰ΩúÊàê
    console.log('üìã Creating temporary table...')
    await client.query(`
      CREATE TEMPORARY TABLE temp_prtimes_seed (
        delivery_date text,
        press_release_url text,
        press_release_title text,
        press_release_type text,
        press_release_category1 text,
        press_release_category2 text,
        company_name text,
        company_website text,
        business_category text,
        address text,
        phone_number text,
        representative text,
        listing_status text,
        capital_amount_text text,
        established_date_text text,
        capital_amount_numeric text,
        established_year text,
        established_month text
      )
    `)

    // COPY„Ç≥„Éû„É≥„Éâ„ÅßË∂ÖÈ´òÈÄü„Ç§„É≥„Éù„Éº„Éà
    console.log('‚ö° Executing COPY command (this is very fast)...')
    const copyStartTime = Date.now()

    const copyResult = await client.query(`
      COPY temp_prtimes_seed
      FROM '${csvFilePath}'
      WITH (FORMAT csv, HEADER true, DELIMITER ',', NULL '')
    `)

    const copyEndTime = Date.now()
    const copyTime = Math.round((copyEndTime - copyStartTime) / 1000)
    console.log(`üì• COPY completed in ${copyTime}s: ${copyResult.rowCount?.toLocaleString()} rows imported`)

    // „Éá„Éº„ÇøÂ§âÊèõ„ÉªÊ§úË®º„Åó„Å¶Êú¨„ÉÜ„Éº„Éñ„É´„Å´ÊåøÂÖ•
    console.log('üîÑ Converting and validating data...')
    const insertStartTime = Date.now()

    const insertResult = await client.query(`
      INSERT INTO prtimes_companies (
        delivery_date, press_release_url, press_release_title, press_release_category1,
        press_release_category2, company_name, company_website, business_category,
        listing_status, press_release_type, address, phone_number, representative,
        capital_amount_text, established_date_text, capital_amount_numeric,
        established_year, established_month, batch_id
      )
      SELECT
        CASE
          WHEN delivery_date IS NULL OR delivery_date = '' THEN NOW()
          ELSE COALESCE(delivery_date::timestamp, NOW())
        END,
        COALESCE(SUBSTRING(press_release_url, 1, 1000), ''),
        COALESCE(press_release_title, ''),
        COALESCE(SUBSTRING(press_release_category1, 1, 100), ''),
        COALESCE(SUBSTRING(press_release_category2, 1, 100), ''),
        COALESCE(SUBSTRING(company_name, 1, 255), ''),
        CASE
          WHEN company_website IS NULL OR company_website = '' THEN NULL
          ELSE SUBSTRING(company_website, 1, 1000)
        END,
        COALESCE(SUBSTRING(business_category, 1, 100), ''),
        COALESCE(SUBSTRING(listing_status, 1, 200), ''),
        COALESCE(SUBSTRING(press_release_type, 1, 100), ''),
        COALESCE(SUBSTRING(address, 1, 500), ''),
        COALESCE(SUBSTRING(phone_number, 1, 100), ''),
        COALESCE(SUBSTRING(representative, 1, 200), ''),
        COALESCE(SUBSTRING(capital_amount_text, 1, 200), ''),
        COALESCE(SUBSTRING(established_date_text, 1, 100), ''),
        CASE
          WHEN capital_amount_numeric IS NULL OR capital_amount_numeric = '' THEN NULL
          ELSE capital_amount_numeric::integer
        END,
        CASE
          WHEN established_year IS NULL OR established_year = '' THEN NULL
          ELSE established_year::integer
        END,
        CASE
          WHEN established_month IS NULL OR established_month = '' THEN NULL
          ELSE established_month::integer
        END,
        $1
      FROM temp_prtimes_seed
      WHERE company_name IS NOT NULL AND company_name != ''
    `, [batchId])

    successCount = insertResult.rowCount || 0
    const totalProcessed = copyResult.rowCount || 0
    errorCount = totalProcessed - successCount

    const insertEndTime = Date.now()
    const insertTime = Math.round((insertEndTime - insertStartTime) / 1000)
    console.log(`‚úÖ Data conversion completed in ${insertTime}s: ${successCount.toLocaleString()} records inserted`)

    // „Ç§„É≥„Éá„ÉÉ„ÇØ„ÇπÂÜçÊßãÁØâ
    console.log('üî® Rebuilding indexes...')
    const indexStartTime = Date.now()

    await client.query('CREATE INDEX IF NOT EXISTS idx_prtimes_company_name ON prtimes_companies(company_name)')
    await client.query('CREATE INDEX IF NOT EXISTS idx_prtimes_website ON prtimes_companies(company_website)')

    const indexEndTime = Date.now()
    const indexTime = Math.round((indexEndTime - indexStartTime) / 1000)
    console.log(`üî® Indexes rebuilt in ${indexTime}s`)

    // Áµ±Ë®àÊÉÖÂ†±Êõ¥Êñ∞
    console.log('üìä Updating table statistics...')
    await client.query('ANALYZE prtimes_companies')

    // „Ç¢„ÉÉ„Éó„É≠„Éº„ÉâÂ±•Ê≠¥„ÇíÊõ¥Êñ∞
    const status = errorCount === 0 ? 'completed' : (successCount > 0 ? 'partial' : 'failed')
    await client.query(`
      UPDATE prtimes_uploads
      SET success_records = $1, error_records = $2, status = $3, progress_count = $4
      WHERE id = $5
    `, [successCount, errorCount, status, successCount + errorCount, uploadId])

    const endTime = Date.now()
    const totalTime = Math.round((endTime - startTime) / 1000)

    // ÁµêÊûúË°®Á§∫
    console.log('\nüéâ Bulk import completed!')
    console.log('=' * 50)
    console.log(`‚è±Ô∏è  Total time: ${totalTime}s (${Math.round(totalTime/60)}m${totalTime%60}s)`)
    console.log(`‚úÖ Success: ${successCount.toLocaleString()} records`)
    console.log(`‚ùå Errors: ${errorCount.toLocaleString()} records`)
    console.log(`üìä Success rate: ${Math.round(successCount / totalProcessed * 100)}%`)
    console.log(`üöÄ Speed: ${Math.round(successCount / totalTime).toLocaleString()} records/second`)
    console.log(`üÜî Batch ID: ${batchId}`)
    console.log('=' * 50)

    // „Éë„Éï„Ç©„Éº„Éû„É≥„ÇπÊØîËºÉ
    const oldMethodTime = Math.round(totalProcessed * 0.6) // 1‰ª∂0.6Áßí„Å®‰ªÆÂÆö
    const speedImprovement = Math.round(oldMethodTime / totalTime)
    console.log(`\nüìà Performance comparison:`)
    console.log(`Old method (1-by-1): ~${Math.round(oldMethodTime/3600)}h ${Math.round((oldMethodTime%3600)/60)}m`)
    console.log(`New method (COPY): ${Math.round(totalTime/60)}m ${totalTime%60}s`)
    console.log(`Speed improvement: ${speedImprovement}x faster! üöÄ`)

    if (successCount > 0) {
      console.log('\nüí° You can now use the data in your application!')
      console.log('The search cache will be automatically updated.')
    }

  } catch (error) {
    console.error('‚ùå Bulk import error:', error)

    // „Ç®„É©„ÉºÊôÇ„ÅÆ„Çπ„ÉÜ„Éº„Çø„ÇπÊõ¥Êñ∞
    try {
      await client.query(`
        UPDATE prtimes_uploads
        SET status = 'failed', error_records = $1
        WHERE batch_id = $2
      `, [1, batchId])
    } catch (updateError) {
      console.error('Failed to update error status:', updateError)
    }

    process.exit(1)
  } finally {
    client.release()
    await pool.end()
  }
}

// „Ç≥„Éû„É≥„Éâ„É©„Ç§„É≥ÂºïÊï∞„ÅÆÂá¶ÁêÜ
const args = process.argv.slice(2)
if (args.length === 0) {
  console.log('Usage: node scripts/bulk-import-prtimes.js <path-to-csv-file>')
  console.log('')
  console.log('Example:')
  console.log('  node scripts/bulk-import-prtimes.js /path/to/prtimes-data.csv')
  console.log('  node scripts/bulk-import-prtimes.js ~/Downloads/large-prtimes.csv')
  console.log('')
  console.log('Benefits:')
  console.log('  ‚Ä¢ 100x-200x faster than web upload')
  console.log('  ‚Ä¢ Handles files of any size')
  console.log('  ‚Ä¢ Built-in error handling and progress tracking')
  console.log('  ‚Ä¢ Automatic index optimization')
  process.exit(1)
}

const csvFilePath = path.resolve(args[0])
bulkImportPRTimes(csvFilePath)